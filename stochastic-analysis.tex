
\paragraph{Independent increments and filtations.} Let $X = (X_t)_{t\geq 0}$ be
a stochastic process with independent increments, i.e.\ for all $0=t_{0}\leq t_1
\dots \leq t_n$ the random elements $X_0, X_{t_1}-X_{t_1},\dots
,X_{t_n}-X_{t_{n-1}}$ are independent.
\begin{enumerate}
    \item Show that $X_t -X_s \upmodels \cF_{s}^{X}$ for all $0\leq s\leq t$. 
\end{enumerate}

\paragraph*{Solution.} Note that the $\sigma$-algebra induced by $f(X_0)$ for a
measurable function $f$ is smaller than $\sigma(X_0)$. Therefore $\sigma(X_s)
\subset \sigma(X_0, X_s-X_0)$ and by assumption $\sigma(X_s) \upmodels
\sigma(X_t-X_s)$. By the grouping theorem \cite[p. 51]{Kallenberg}, we get
$X_{t}-X_{s}\upmodels \cF_s^{X}$. 


\paragraph{Borel sets in Euclidean space are regular.} $Q$ is a probability
measure on $(\bR, \cB(\bB))$ and $\varepsilon>0$ a fixed real number. Then
every set in $(\bR, \cB(\bR))$ is regular. This means there is a closed set $F$
and an open set $G$ with $F\subset A \subset G$ such that $Q(G\setminus
F)<\varepsilon$ for arbitrary $\varepsilon>0$. 


\paragraph{Filtations and continuity of paths.} Let $X$ be a stochastic process
on a probability space $(\Omega, \cA, P)$ and $\cF^{X}=(\cF^{X}_{t})_{t\geq 0}$
be the natural filtration of $X$. Moreover, $A$ is the event that $X$ is
continuous on $[0, t_0)$. Then following holds:
\begin{enumerate}
    \item If $X$ has c\`adl\`ag paths, i.e. every path of $X$ is a c\`adl\`ag
        function, then $A\in \cF^{X}_{t_0}$. 

    \item If $X$ is c\`adl\`ag, i.e. $X$ has c\`adl\`ag paths a.s., then $A$
        may fail to be in $\cF^{X}_{t_0}$.

    \item If $X$ is c\`adl\`ag, and $(\cF_{t})_{t\geq 0}$ is a filtration
        containing $\cF^{X}$ such that $\cF_{0}$ contains all $P$-null events
        in $\cA$, then $A\in \cF_{t_0}$.

    \item If $X$ has c\`agl\`ad paths and is adapted to a right-continuous
        filtration $(\cF_{t})_{t\geq 0}$, then $A\in \cF_{t_{0}}$. 
\end{enumerate}

\paragraph{Pfadeigenschaften und Filtration. }  Sei $X$ ein stochastischer
Prozess, $\cF^{X}$ die von $X$ erzeugte Filtration und $\cG$ eine Filtration,
die alle $\cF$-Nullmengen enthält und $\cF^{X}_t \subset \cG_t$ $\forall t$
erfüllt.  Sei $A \subset \Omega$ das Ereignis, dass $X$ stetig auf $[0, t_0)$
ist. 
\begin{enumerate}
    \item Falls alle Pfade von $X$ c\`adl\`ag sind, dann ist $A \in \cF^{X}_{t_0}$.
    \item Falls $X$ c\`adl\`ag ist, dann gilt $A \in \cG_{t_0}$, aber nicht
        notwendigerweise $A \in \cF^{X}_{t_0}$.
\end{enumerate}
%\cite{Karatzas1991}.

\paragraph{Messbarkeitsbegriffe. } Sei $X$ ein stochastischer Prozess. Ist $X$
progressiv messbar, so folgt $X$ ist messbar und adaptiert.


\paragraph{Stoppzeiten. } Seien $T,S$ Stoppzeiten bezüglich der Filtration
$\left( \cF_t \right)_{t \geq 0}$. 
\begin{enumerate}
    \item Ist $T \equiv t_0>0$ eine fixe Zeit, so ist $\cF_T=\cF_{t_0}$.
\end{enumerate}

\paragraph*{Lösung. }
\begin{enumerate}
    \item \begin{eqnarray}
            \cF_T &=& 
            \left\{ A\in\bF : A \cap \left\{ t_0 \leq t \right\}\in\cF_t \ \forall t\geq 0 \right\} \\
            &=& \left\{ A\in\bF : A\in\cF_t \ \forall t\geq t_0 \right\} = \cF_{t_0}.
        \end{eqnarray}
\end{enumerate}


\paragraph{Stoppzeiten und optionale Zeiten. } Eine optionale Zeit $T$ bezüglich
der Filtration $\bF=\left( \cF_t \right)_{t \geq 0}$ ist eine Stoppzeit, wenn 
$\bF$ rechtsstetig ist, d.h.\ $\cF_t=\cF_{t+}$ $\forall t$ gilt.

\paragraph*{Lösung.}  Betrachte die Darstellung
\begin{eqnarray}
    \left\{ T \leq t \right\} = \bigcap_{\varepsilon\in\bQ^{+}} \left\{ T > t+\varepsilon \right\}
    = \lim_{\varepsilon\to 0, \varepsilon\in\bQ} \left\{ T > t+\varepsilon \right\}.
\end{eqnarray}
Der Schnitt ist als Mengengrenzwert zu verstehen, weil die Mengen $\left\{ T >
t+\varepsilon \right\}$ ineinandergeschachtelt sind. $\left\{ T \leq t \right\}\in \bF_{t+}$
genau dann, wenn $\left\{ T \leq t \right\}\in \bF_{t+\varepsilon^{*}}$ $\forall \varepsilon^{*}>0$.
Es gilt aber für ein fixes $\varepsilon^{*}$
\begin{equation}
    \left\{ T \leq t \right\}\ = 
    \bigcap_{\varepsilon\in\bQ^{+}, \varepsilon\leq \varepsilon^{*}} \left\{ T > t+\varepsilon \right\} 
    \in\bF_{t+\varepsilon^{*}},
\end{equation}
denn es ein abzählbarer Schnitt der Mengen $\left\{ T> t+\varepsilon
\right\}\in\bF_{t+\varepsilon^{*}}$ ist. Behauptung gilt wegen $\cF_t=\cF_{t+}$ $\forall t$.


\section{Brownsche Bewegung}

\paragraph{Brownian Motion. Finite-dimensional distributions. } 
Let $0=s_0 < s_1 < \cdots < s_n$ be positive real numbers and $(B_{s_{1}},\dots ,B_{s_n})$ 
be a $n$-dimensional random vector with density given by
\begin{equation*}
    f(y_1,\dots ,y_n) = p(s_1, y_1, 0)p(s_2-s_1,y_2, y_1)\dots p(s_n-s_{n-1}, y_n, y_{n-1})
\end{equation*}
with 
\begin{equation*}
    p(t, x,y ) = \frac{1}{\sqrt{2\pi t}} \exp(-\frac{(x-y)^2}{2t}). 
\end{equation*}
Show that:
\begin{enumerate}
    \item The random variables $(B_{s_1}, B_{s_2}-B_{s_1},\dots ,B_{s_n}-B_{s_{n-1}})$ 
        are independent.
    \item The distribution of $B_{s_i}-B_{s_{i-1}}$ is $\cN(0, s_{i}-s_{i-1})$.
\end{enumerate}

\paragraph*{Solution.} Use Jacobi's transformation formula with
$g:\bR^{n}\to\bR^{n}, (y_1,\dots ,y_n)\mapsto(y_1, y_2-y_1,\dots
,y_n-y_{n-1})$. 
\url{https://www.evernote.com/shard/s225/sh/ae5c45ce-9ba1-494b-9039-e166b67e003d/f5c2b31ffec2f92eb568eebc98210970}


\paragraph{Maximum processes of the Brownian Motion. } Show that the process $W
- W^*$ has independent increments. $W$ denotes Brownian Motion and $X^*_t=
\max_{0 \leq s \leq t} X_s$ is the maximum process of a c\`adl\`ag process $X$.


\paragraph{Brownsche Bewegung. Einfache Eigenschaften.}
Sei $W$ eine standard Brownsche Bewegung in $\R^d$, d.h.\ die Identitätsmatrix
ist die Kovarianzmatrix von $W$. Zeigen Sie folgende Aussagen. 
\begin{enumerate}
    \item Sei $A\in \R^{d \times d}$ eine Matrix. Dann ist der Prozess $\tilde W = AW$ eine
        Brownsche Bewegung mit der Kovarianzmatrix $A A^{\top}$. 
    \item Die charakteristische Funktion von $\tilde W$ ist gegeben durch
        \begin{equation*}
            \psi_{\tilde W_t} (u) = \exp \left( -\frac{1}{2} u^{\top} A A^{\top} u \right).
        \end{equation*}
\end{enumerate}

\paragraph*{Lösung.}
\begin{enumerate}
    \item Wegen $\E \tilde W_t=0$ erhalten wir 
        \begin{align*}
            \cov \left( \tilde W_t^{i}, \tilde W_t^{j} \right) 
            &= \E \tilde W_t^i \tilde W_t^j \\
            &= \E \sum_{k=1}^{n} a_{ik} W_t^k \sum_{k=1}^{n} a_{jk} W_t^j \\
            &= \sum_{k=1}^{n} a_{ik} a_{jk} \left( W_t^k \right)^2 \\
            &= \sum_{k=1}^{n} a_{ik} a_{jk} t \\
            &= \left( B B^\top \right)_{ij} t.
        \end{align*}
    \item Ist $\psi_X(u)$ eine charakteristische Funktion einer Zufallsvariable 
        $X$, so ist die charakteristische Funktion von $AX$ für eine Matrix $A$ gegeben
        durch
        \begin{equation*}
            \psi_{AX}(u) = \psi_{X}(A^\top u). 
        \end{equation*}
        Das ist eine Folgerung der Beobachtung $\langle u, AX \rangle = \langle
        A^\top u, X \rangle$. Nun wissen wir, dass
        \begin{equation*}
            \psi_X(u) = \exp \left( - \frac{1}{2} u^\top I u \right). 
        \end{equation*}
        Daraus folgt
        \begin{equation*}
            \psi_{AX}(u) = \psi_X(A^\top u) = 
            \exp \left( -\frac{1}{2} u^\top AA^\top u \right).
        \end{equation*}
\end{enumerate}


\paragraph{Brownsche Bewegung. Lokales Verhalten. }
Sei $B$ eine standard Brownsche Bewegung auf $(\Omega, \cF, P)$. Definiere die
Niveaumenge 
\begin{equation*}
    \cL_{\omega}^{\alpha} = \left\{ t\in\R_{\geq 0} : B_t(\omega)=\alpha \right\}
\end{equation*}
für ein $\omega\in\Omega$ und ein $\alpha\in\R$. 
Beweisen Sie folgende Aussagen:
\begin{enumerate}
    \item $\limsup_{t\to \infty} \frac{B_t}{\sqrt{t}} > 0$, $P$ fast sicher. 
    \item Die Niveaumenge $\cL_\omega^{0}$ hat an Null einen Häufungspunkt
        für fast alle $\omega\in \Omega$. 
    \item Brownsche Bewegung ist rekurrent, d.h.\ $L_\omega^{\alpha}$ ist für alle
        $\alpha\in\R$ $P$ fast sicher unbeschränkt. 
    \item Die Pfade von $B$ sind f.s.\ nirgends lokal Hölder stetig für alle 
        $\alpha>\frac{1}{2}$. Eine reellwertige Funktion $f$ ist lokal Hölder
        stetig der Ordnung $0<\alpha\leq 1$, wenn 
        \begin{equation*}
            \sup_{t,s} \left\{ \frac{ | f(t)-f(s) | }{ | t-s |^{\alpha}} : 
            |t|,|s| \leq L, t\neq s \right\} < \infty
        \end{equation*}
        für alle positiven $L$ gilt. 
\end{enumerate}
\paragraph*{Lösung.} 
\begin{enumerate}
    \item Wir setzen $A=\limsup_{t\to \infty} \frac{B_t}{\sqrt{t}}$. Angenommen
        es gilt $A\leq 0$, $P$-f.s. Aus Symmetriegründen muss also
        \begin{equation*}
            \lim_{t\to\infty} \frac{B_t}{\sqrt{t}} = 0 \ P-\text{f.s.}
        \end{equation*}
        gelten. Mit $\frac{B_t}{\sqrt{t}}\sim \cN(0,1)$ erhalten wir einen Widerspruch.
    \item Um das obige Resultat zu benutzen, berechnen wir
        \begin{equation*}
            \limsup_{t\to\infty} \frac{B_t}{\sqrt{t}} = 
            \limsup_{t\to 0} \sqrt{t} B_{1/t} = 
            \limsup_{t\to 0} \frac{t B_{1/t}}{\sqrt{t}}. 
        \end{equation*}
        Der Prozess $X_t = t B_{1/t}$ ist ebenfalls eine Brownsche Bewegung und
        es gilt
        \begin{align*}
            \limsup_{t\to 0} \frac{X_t}{\sqrt{t}} & > 0 \ P-\text{f.s.} \\
            \liminf_{t\to 0} \frac{X_t}{\sqrt{t}} & < \ P-\text{f.s.}.
        \end{align*}
        Fast jeder Pfad von $X$ muss in jeder Umgebung von $0$ unendlich oft
        das Vorzeichen wechseln, also hat die Menge der Nullstellen einen
        Häufungspunkt. 
    \item Nachdem die Nullstellen fast aller Pfade von $B$ einen Häufungspunkt bei
        $0$ haben und der Prozess $X_t = t B_{1/t}$ eine Brownsche Bewegung ist,
        ist die Menge der Nullstellen unbeschränkt. Somit erhalten wir 
        $\cL^{0}$ fast sicher unbeschränkt. \todo{Beweis für beliebige Niveaus fehlt noch. }
    \item Für den Beweis der Hölderstetigkeit betrachten wir
        \begin{equation*}
            \frac{| B_t - B_s|}{ |t-s|^{\frac{1}{2}+\varepsilon} } = 
            \frac{X}{|t-s|^{\varepsilon}}
        \end{equation*}
        wobei
        \begin{equation*}
            X = \frac{| B_t - B_s|}{ |t-s|^{\frac{1}{2}}} \sim \cN(0,1).
        \end{equation*}
        Nachdem aber $\varepsilon>0$, ist
        \begin{equation*}
            \sup_{|t|,|s| \leq L, t\neq s} \frac{|X|}{|t-s|^{\varepsilon}}
        \end{equation*}
        unbeschränkt. 
\end{enumerate}



\section{L\'evy Prozesse}

\paragraph{Faltungshalbgruppe.}
Sei eine Faltungshalbgruppe, d.h.\ eine Familie $G=(\mu_t)_{t\geq 0}$ von
Wahrscheinlichkeitsmaßen mit der Eigenschaft $\mu_t * \mu_s = \mu_{t+s}$ und
$\mu_0 = \delta_0$ gegeben. Zeigen Sie, dass die folgenden Aussagen äquivalent
sind.
\begin{enumerate}
    \item Für alle Testfunktionen $f\in C_b(\R^d)$ gilt
        \begin{equation*}
            \lim_{t\downarrow 0} \int_{}^{} f(y) \mu_t(dy) = f(0).
        \end{equation*}
    \item Für alle Testfunktionen $f\in C_b(\R^d)$ und alle $s>0$ gilt
        \begin{equation*}
            \lim_{t\downarrow s} \int_{}^{} f(y) \mu_t(dy) =
            \int_{}^{} f(y) \mu_s(dy). 
        \end{equation*}
\end{enumerate}

\paragraph{Poissonprozess. Charakteristische Funktion. } Sei $N$ ein
Poissonprozess mit dem Parameter $\lambda>0$ gegeben. $N$ is also ein L\'evy
Prozess mit den Werten in $\bN$ und 
\begin{equation*}
    P(N_t = n) = e^{- \lambda t} \frac{ (\lambda t)^n}{ n!}.
\end{equation*}
\begin{enumerate}
    \item Die charakteristische Funktion von $N_t$ ist 
        \begin{equation*}
            \psi_t(u) = \E \exp iu N_t = \exp \left( \lambda t \left( e^{iu} -1\right) \right).
        \end{equation*}
    \item Die charakteristische Funktion des kompensierten Poissonprozesses
        $\tilde N_t = N_t - \lambda t$ ist 
        \begin{equation*}
            \tilde \psi_t (u) = \E \exp iu \tilde N_t = 
            \exp \left( \lambda t \left( e^{it}-1-iu \right) \right). 
        \end{equation*}
\end{enumerate} 

\paragraph*{Lösung.} Eine einfache Rechnung liefert
\begin{align*}
    \E \exp iu N_t &= \sum_{n\geq 0}^{} \exp \left( iun  \right) P (N_t = n) \\
    &= \sum_{n\geq 0}^{} \exp \left( iun \right) e^{-\lambda t} \frac{(\lambda t)^n}{n!} \\
    &= \exp \left( \lambda t \left( e^{iu}-1 \right) \right). 
\end{align*}
Nachdem $e^{i u \lambda t}$ die charakteristische Funktion des Dirac-masses an 
$\lambda t$ ist, erhalten wir 
\begin{equation*}
    \tilde \psi_t(u) = \E \exp \left( i u N_t \right) = 
    \exp \left( \lambda t \left( e^{iu}-1-iu \right) \right). 
\end{equation*}

\paragraph{Zusammengesetzter Poissonprocess. Charakteristische Funktion.}
Sei $X$ ein zusammengesetzter Poissonprozess mit dem Parameter $\lambda>0$ und
der Sprungverteilung $\nu$ auf $\R^d$ mit $\nu(\{0\})=0$. 
\begin{enumerate}
    \item Die charakteristische Funktion von $X_t$ ist gegeben durch
        \begin{equation*}
            \psi_t(u) = \exp \left( \lambda t \int_{}^{} e^{iuy}-1 \, \nu(dy) \right). 
        \end{equation*}
    \item Die charakteristische Funktion von dem kompensierten zusammengesetzten
        Poissonprozess $\tilde X_t = X_t - \E X_t$ ist gegeben durch
        \begin{equation*}
            \tilde \psi_t(u) = \exp \left( \lambda t \int e^{iuy}-1-iuy \, \nu(dy) \right). 
        \end{equation*}
\end{enumerate}

\paragraph*{Lösung.} Bei der Berechnung benutzen wir die Eigenschaften der bedingten
Erwartung.
\begin{align*}
    \psi_t (u) &= \E \exp iu X_t \\
    &= \E \E \left[ \left. \exp \left( iu \sum_{i=1}^{N_t} Y_i \right) \right| \left( N_s \right)_{s\in [0,t]} \right] \\
    &= \sum_{n \geq 0}^{} \left( \int_{\R^d} e^{iu x} \, \nu(dx) \right)^n P(N_t = n) \\
    &= \sum_{n \geq 0}^{} \left( \int_{} e^{iu x} \, \nu(dx) \right)^n
        e^{-\lambda t} \frac{(\lambda t)^n}{n!} \\
    &= \exp \left( \lambda t \int e^{iux}-1 \, \nu(dx) \right).
\end{align*}
Wir brauchen nur noch den Erwartungswert von $X_t$ zu berechnen. 
\begin{align*}
    \E X_t &= \sum_{n \geq 0}^{} n \left( \int_{\R^d} x\, \nu(dx) \right) 
    e^{-\lambda t} \frac{(\lambda t)^n}{n!} \\
    &= \int_{}^{} x \, \nu(dx) \sum_{n \geq 0} n e^{-\lambda t} \frac{(\lambda t)^n}{n!} \\
    &= \lambda t \int_{}^{} x \, \nu (dx). 
\end{align*}
Insgesamt erhalten wir 
\begin{equation*}
    \tilde \psi_t (u) = \exp \left( \lambda t \int_{\R^d} e^{iux}-1-iux \, \nu(dx) \right).
\end{equation*}





\paragraph{L\'evy martingales.} Every Levy process which is a local martingale is
also a true martingale.



\section{Markov Prozesse}

\paragraph{Not Feller by discontinuity at zero.}
Find a Markov process viotating the continuity part of 
the Feller property, namely
\begin{equation}
\lim_{t\to 0} P_t f(x) = f(x) \quad \forall f \in C_0 \ \forall x\in \R
\end{equation}
but perhaps preserving the $C_0$ property $P_t C_0 \subset C_0$.



\paragraph{Independence and transformations. } Let random variables
$X_1,\ldots,X_n$ and $Y_1,\ldots,Y_k$ satisfy $X_i \upmodels Y_j$ for all $i$
and $i$.
\begin{enumerate}
    \item It follows that $g(X_i)$ and $h(Y_j)$ are independent for any $i$ and
        $j$.
    \item A generalization of the above result is not true. Given any Borel
        functions $f$ and $g$ of suitable dimensionality $f(X_1,\ldots,X_n)$
        may be not independent of $g(Y_1,\ldots,Y_k)$.
\end{enumerate}



\section{Stochastische Integration}

\paragraph{Stieltjes-Integrale der Brownschen Bewegung.} 
Sei $B$ eine Brownsche Bewegung und eine Funktion $X:\Omega\to\R$ definiert durch
\begin{equation*}
    X(\omega) = \int_{0}^{1} B_s^{2} ds. 
\end{equation*}
\begin{enumerate}
    \item Zeigen Sie, dass $X$ eine Zufallsvariable ist.
    \item Berechnen Sie den ersten und zweiten Moment von $X$. 
\end{enumerate}



\paragraph{Stochastisches Integral einer deterministischen Funktion. } Sei
$f: \R\in\R$ eine deterministische meßbare Funktion. Zeigen Sie 
\begin{equation}
    \int_{0}^{t} f(s) d W_s \sim \cN(0, \int_{0}^{t} f^2(s) ds). 
\end{equation}








\section{Stochastische Differentialgleichungen. }

\paragraph{Ornstein-Uhlenbeck SDE.} Lösen Sie die \textsc{SDE}
\begin{equation}
    dX_t = \left( \alpha-\beta X_t \right)dt + \sigma dW_t, \quad X_0\in\R.
\end{equation}
Die Parameter $\alpha, \beta$ und $\sigma$ sind reelle Zahlen und $\sigma>0$. 
\begin{enumerate}
    \item Zeigen Sie mit Hilfe der Funktion $f(t,x)=x\exp(\beta t)$ und der It\^o-Formel, dass
        \begin{eqnarray}
            X_t = e^{-\beta t} X_0 + \frac{\alpha}{\beta}\left( 1-e^{-\beta t} \right)
                       + \sigma \int_{0}^{t} e^{\beta(s-t)} d W_s.
        \end{eqnarray}
    \item Leiten Sie aus der von Ihnen gefundenen Lösung die Identitäten
        \begin{eqnarray}
            \E X_t &=& e^{-\beta t} X_0 + \frac{\alpha}{\beta}\left( 1-e^{-\beta t} \right) \\
            \Var X_t &=& \frac{\sigma^2}{2\beta}\left( 1- e^{-2\beta t} \right)
        \end{eqnarray} 
        her.
    \item Zeigen Sie, dass $X_t$ normalverteilt ist. 
\end{enumerate}

\paragraph*{Lösung. } Die Lösung ergibt sich durch die Anwendung der It\^o-Formel
auf die Funktion $f$. Da $\int_{}^{} g(s) d W_s$ für progressiv meßbares $g$ ein
Martingal ist, erhalten wir $\E X_t$ direkt aus der Lösung. Die Formel für die 
Varianz folgt mit Hilfe der It\^o-Isometrie.



